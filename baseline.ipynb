{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sacred-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "impossible-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.txt', header=None, names=['pid', 'label', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "test = pd.read_csv('data/test.txt', header=None, names=['pid', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "wired-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计特征\n",
    "for col in ['gender', 'age', 'province', 'city']:\n",
    "    data['{}_count'.format(col)] = data.groupby(col)[col].transform('count')\n",
    "    \n",
    "corss_feature = ['gender', 'age', 'province', 'city']\n",
    "# 交叉组合统计，就是组合特征的共现频次\n",
    "while len(corss_feature) != 0:\n",
    "    f = corss_feature.pop()\n",
    "    for col in corss_feature:\n",
    "        data['{}_{}_count'.format(f, col)] = data.groupby([f, col])[col].transform('count')\n",
    "        \n",
    "# 特征unique count特征\n",
    "for index, col1 in enumerate(['age', 'province', 'city']):\n",
    "    for col2 in ['age', 'province', 'city'][index:]:\n",
    "        data['{}_in_{}_count'.format(col1, col2)] = data.groupby(col1)[col2].transform('count')\n",
    "        data['{}_in_{}_nunique'.format(col1, col2)] = data.groupby(col1)[col2].transform('nunique')\n",
    "        data['{}_in_{}_nunique/{}_in_{}_count'.format(col1, col2, col1, col2)] = data['{}_in_{}_nunique'.format(col1,\n",
    "                                                                                                                col2)] / \\\n",
    "                                                                                 data['{}_in_{}_count'.format(col1,\n",
    "                                                                                                              col2)]\n",
    "\n",
    "        data['{}_in_{}_count'.format(col2, col1)] = data.groupby(col2)[col1].transform('count')\n",
    "        data['{}_in_{}_nunique'.format(col2, col1)] = data.groupby(col2)[col1].transform('nunique')\n",
    "        data['{}_in_{}_nunique/{}_in_{}_count'.format(col2, col1, col2, col1)] = data['{}_in_{}_nunique'.format(col2,\n",
    "                                                                                                                col1)] / \\\n",
    "                                                                                 data['{}_in_{}_count'.format(col2,\n",
    "                                                                                                              col1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "isolated-concept",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [01:05<00:00, 6078.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# tagid word2vec特征\n",
    "data['tagid'] = data['tagid'].apply(lambda x: eval(x))\n",
    "sentences = data['tagid'].values.tolist()\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i] = [str(x) for x in sentences[i]]\n",
    "emb_size = 32\n",
    "model = Word2Vec(sentences, vector_size=emb_size, window=6, min_count=5, sg=0, hs=0, seed=1, epochs=5)\n",
    "emb_matrix = []\n",
    "for seq in tqdm(sentences):\n",
    "    vec = []\n",
    "    for w in seq:\n",
    "        if w in model.wv.key_to_index:\n",
    "            vec.append(model.wv[w])\n",
    "    if len(vec) > 0:\n",
    "        emb_matrix.append(np.mean(vec, axis=0))\n",
    "    else:\n",
    "        emb_matrix.append([0] * emb_size)\n",
    "emb_matrix = np.array(emb_matrix)\n",
    "for i in range(emb_size):\n",
    "    data['tag_emb_{}'.format(i)] = emb_matrix[:, i]\n",
    "    \n",
    "# tagid tfidf特征\n",
    "data['tagid'] = data['tagid'].apply(lambda x: ' '.join(map(str,x)))\n",
    "clf_tfidf = TfidfVectorizer(max_features=30)\n",
    "tfidf=clf_tfidf.fit_transform(data['tagid'])\n",
    "tfidf = pd.DataFrame(tfidf.toarray())\n",
    "tfidf.columns = ['tagid_tfidf_' + str(x) for x in range(30)]\n",
    "data = pd.concat([data, tfidf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "first-relevance",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "trn_idx: [     0      1      2 ... 299997 299998 299999]\n",
      "val_idx: [     3      9     14 ... 299992 299993 299994]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.288733\tvalid_1's binary_error: 0.308517\n",
      "[200]\ttraining's binary_error: 0.270492\tvalid_1's binary_error: 0.3062\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's binary_error: 0.270492\tvalid_1's binary_error: 0.3062\n",
      "fold n°1\n",
      "trn_idx: [     0      1      2 ... 299996 299998 299999]\n",
      "val_idx: [    10     13     25 ... 299986 299988 299997]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.288637\tvalid_1's binary_error: 0.309817\n",
      "[200]\ttraining's binary_error: 0.270087\tvalid_1's binary_error: 0.305983\n",
      "[300]\ttraining's binary_error: 0.259467\tvalid_1's binary_error: 0.305533\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttraining's binary_error: 0.257283\tvalid_1's binary_error: 0.305217\n",
      "fold n°2\n",
      "trn_idx: [     0      3      5 ... 299997 299998 299999]\n",
      "val_idx: [     1      2      4 ... 299961 299977 299982]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.288429\tvalid_1's binary_error: 0.310217\n",
      "[200]\ttraining's binary_error: 0.270808\tvalid_1's binary_error: 0.307133\n",
      "[300]\ttraining's binary_error: 0.259487\tvalid_1's binary_error: 0.306667\n",
      "[400]\ttraining's binary_error: 0.251371\tvalid_1's binary_error: 0.3061\n",
      "Early stopping, best iteration is:\n",
      "[378]\ttraining's binary_error: 0.2533\tvalid_1's binary_error: 0.305317\n",
      "fold n°3\n",
      "trn_idx: [     0      1      2 ... 299993 299994 299997]\n",
      "val_idx: [     5      6     12 ... 299996 299998 299999]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.289004\tvalid_1's binary_error: 0.309617\n",
      "[200]\ttraining's binary_error: 0.270746\tvalid_1's binary_error: 0.306133\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's binary_error: 0.265096\tvalid_1's binary_error: 0.305067\n",
      "fold n°4\n",
      "trn_idx: [     1      2      3 ... 299997 299998 299999]\n",
      "val_idx: [     0      7      8 ... 299967 299972 299973]\n",
      "[LightGBM] [Warning] Unknown parameter: colsample_btree\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's binary_error: 0.288587\tvalid_1's binary_error: 0.30925\n",
      "[200]\ttraining's binary_error: 0.2712\tvalid_1's binary_error: 0.305667\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttraining's binary_error: 0.265729\tvalid_1's binary_error: 0.304433\n",
      "AUC score: 0.7650294097999999\n",
      "F1 score: 0.6900524623455745\n",
      "Precision score: 0.700845651426607\n",
      "Recall score: 0.6795866666666667\n"
     ]
    }
   ],
   "source": [
    "cat_cols = ['gender', 'age', 'province', 'city']\n",
    "features = [i for i in data.columns if i not in ['pid', 'label', 'tagid', 'time', 'model', 'make']]\n",
    "data[cat_cols] = data[cat_cols].astype('category')\n",
    "X_train = data[~data['label'].isna()]\n",
    "X_test = data[data['label'].isna()]\n",
    "\n",
    "y = X_train['label']\n",
    "KF = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "params = {\n",
    "          'objective':'binary',\n",
    "          'metric':'binary_error',\n",
    "          'learning_rate':0.05,\n",
    "          'subsample':0.8,\n",
    "          'subsample_freq':3,\n",
    "          'colsample_btree':0.8,\n",
    "          'num_iterations': 10000,\n",
    "          'verbose':-1\n",
    "}\n",
    "oof_lgb = np.zeros(len(X_train))\n",
    "predictions_lgb = np.zeros((len(X_test)))\n",
    "# 特征重要性\n",
    "feat_imp_df = pd.DataFrame({'feat': features, 'imp': 0})\n",
    "# 五折交叉验证\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(X_train.values, y.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print('trn_idx:',trn_idx)\n",
    "    print('val_idx:',val_idx)\n",
    "    trn_data = lgb.Dataset(X_train.iloc[trn_idx][features],label=y.iloc[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train.iloc[val_idx][features],label=y.iloc[val_idx])\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(\n",
    "        params,\n",
    "        trn_data,\n",
    "        num_round,\n",
    "        valid_sets = [trn_data, val_data],\n",
    "        verbose_eval=100,\n",
    "        early_stopping_rounds=50,\n",
    "        categorical_feature=cat_cols,\n",
    "    )\n",
    "    feat_imp_df['imp'] += clf.feature_importance() / 5\n",
    "    oof_lgb[val_idx] = clf.predict(X_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    predictions_lgb[:] += clf.predict(X_test[features], num_iteration=clf.best_iteration)\n",
    "print(\"AUC score: {}\".format(roc_auc_score(y, oof_lgb)))\n",
    "print(\"F1 score: {}\".format(f1_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))\n",
    "print(\"Precision score: {}\".format(precision_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))\n",
    "print(\"Recall score: {}\".format(recall_score(y, [1 if i >= 0.5 else 0 for i in oof_lgb])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "compliant-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['category_id'] = [1 if i >= 2.5 else 0 for i in predictions_lgb]\n",
    "X_test['user_id'] = X_test['pid']\n",
    "X_test[['user_id', 'category_id']].to_csv('base3_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ordered-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.txt', header=None, names=['pid', 'label', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "test = pd.read_csv('data/test.txt', header=None, names=['pid', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-analysis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
