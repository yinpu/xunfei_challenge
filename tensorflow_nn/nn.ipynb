{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepctr\n",
    "import tensorflow as tf\n",
    "from myModel import deepFM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.txt', header=None, names=[\n",
    "    'pid', 'label', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "test = pd.read_csv('../data/test.txt', header=None, names=[\n",
    "    'pid', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:23<00:00, 17041.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# 按tagid时间降序排序，筛选出最近50个tagid，不足补0\n",
    "data['tagid'] = data['tagid'].apply(eval)\n",
    "data['time'] = data['time'].apply(eval)\n",
    "all_tag_id = []\n",
    "all_tag_weight = []\n",
    "all_tag_len = []\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    tagid_list = np.array(data.loc[i, 'tagid'])\n",
    "    time_list = np.array(data.loc[i, 'time'])\n",
    "    index = np.argsort(time_list)[::-1][:50]\n",
    "    sort_time_list = time_list[index] / 1000 / 3600 / 24 / 30\n",
    "    sort_tagid_list = tagid_list[index]\n",
    "    latest_time = sort_time_list[0]\n",
    "    tag_weight = [(1 + math.exp(time - latest_time)) / 2 for time in sort_time_list]\n",
    "    all_tag_id.extend(sort_tagid_list.tolist() + [0] * (50 - len(index)))\n",
    "    all_tag_weight.extend(tag_weight + [0] * (50 - len(index)))\n",
    "    all_tag_len.append(len(index))\n",
    "taglbe = LabelEncoder()\n",
    "new_tag_id = taglbe.fit_transform(all_tag_id).reshape(-1, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df1 = pd.DataFrame({\"tagid_history\": new_tag_id.tolist()})\n",
    "new_df2 = pd.DataFrame({\"tagid_weight\": np.array(all_tag_weight).reshape(-1, 50).tolist()})\n",
    "new_df3 = pd.DataFrame({\"tagid_history_len\": all_tag_len})\n",
    "new_data = pd.concat([data, new_df1, new_df2, new_df3], axis=1)\n",
    "\n",
    "# label encoder\n",
    "num_dict = {}  # 每个features的个数\n",
    "embedding_dim_dict = {}  # 每个feature的embedding维度\n",
    "sparse_features = [\"gender\", \"age\", \"province\", \"city\"]\n",
    "target = ['label']\n",
    "new_data[sparse_features] = new_data[sparse_features].fillna(-1)\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    new_data[feat] = lbe.fit_transform(new_data[feat])\n",
    "    num_dict[feat] = len(lbe.classes_)\n",
    "    embedding_dim_dict[feat] = 64\n",
    "num_dict['tagid_history'] = len(taglbe.classes_)\n",
    "embedding_dim_dict['tagid_history'] = 64\n",
    "\n",
    "X_train = new_data[~new_data['label'].isna()]\n",
    "X_test = new_data[new_data['label'].isna()]\n",
    "y = X_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "trn_idx: [     0      1      2 ... 299997 299998 299999]\n",
      "val_idx: [     3      9     14 ... 299992 299993 299994]\n",
      "Train on 240000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "240000/240000 - 21s - loss: 0.5994 - binary_crossentropy: 0.5809 - AUC: 0.7646 - val_loss: 0.5820 - val_binary_crossentropy: 0.5624 - val_AUC: 0.7818\n",
      "Epoch 2/100\n",
      "240000/240000 - 19s - loss: 0.5713 - binary_crossentropy: 0.5511 - AUC: 0.7925 - val_loss: 0.5763 - val_binary_crossentropy: 0.5564 - val_AUC: 0.7877\n",
      "Epoch 3/100\n",
      "240000/240000 - 20s - loss: 0.5620 - binary_crossentropy: 0.5415 - AUC: 0.8012 - val_loss: 0.5766 - val_binary_crossentropy: 0.5566 - val_AUC: 0.7899\n",
      "Epoch 4/100\n",
      "240000/240000 - 19s - loss: 0.5552 - binary_crossentropy: 0.5343 - AUC: 0.8077 - val_loss: 0.5723 - val_binary_crossentropy: 0.5517 - val_AUC: 0.7913\n",
      "Epoch 5/100\n",
      "240000/240000 - 19s - loss: 0.5493 - binary_crossentropy: 0.5279 - AUC: 0.8133 - val_loss: 0.5746 - val_binary_crossentropy: 0.5533 - val_AUC: 0.7915\n",
      "Epoch 6/100\n",
      "240000/240000 - 19s - loss: 0.5445 - binary_crossentropy: 0.5222 - AUC: 0.8182 - val_loss: 0.5725 - val_binary_crossentropy: 0.5506 - val_AUC: 0.7920\n",
      "Epoch 7/100\n",
      "240000/240000 - 19s - loss: 0.5394 - binary_crossentropy: 0.5165 - AUC: 0.8231 - val_loss: 0.5739 - val_binary_crossentropy: 0.5512 - val_AUC: 0.7919\n",
      "Epoch 8/100\n",
      "240000/240000 - 18s - loss: 0.5350 - binary_crossentropy: 0.5112 - AUC: 0.8274 - val_loss: 0.5756 - val_binary_crossentropy: 0.5520 - val_AUC: 0.7911\n",
      "fold n°1\n",
      "trn_idx: [     0      1      2 ... 299996 299998 299999]\n",
      "val_idx: [    10     13     25 ... 299986 299988 299997]\n",
      "Train on 240000 samples, validate on 60000 samples\n",
      "Epoch 1/100\n",
      "240000/240000 - 21s - loss: 0.5984 - binary_crossentropy: 0.5795 - AUC: 0.7655 - val_loss: 0.5813 - val_binary_crossentropy: 0.5615 - val_AUC: 0.7836\n",
      "Epoch 2/100\n",
      "240000/240000 - 19s - loss: 0.5710 - binary_crossentropy: 0.5505 - AUC: 0.7930 - val_loss: 0.5755 - val_binary_crossentropy: 0.5553 - val_AUC: 0.7883\n",
      "Epoch 3/100\n",
      "240000/240000 - 19s - loss: 0.5618 - binary_crossentropy: 0.5410 - AUC: 0.8016 - val_loss: 0.5735 - val_binary_crossentropy: 0.5531 - val_AUC: 0.7899\n",
      "Epoch 4/100\n",
      "240000/240000 - 19s - loss: 0.5549 - binary_crossentropy: 0.5337 - AUC: 0.8081 - val_loss: 0.5725 - val_binary_crossentropy: 0.5515 - val_AUC: 0.7914\n",
      "Epoch 5/100\n"
     ]
    }
   ],
   "source": [
    "KF = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "oof_nn = np.zeros(len(X_train))\n",
    "predictions_nn = np.zeros((len(X_test)))\n",
    "# 五折交叉验证\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(X_train.values, y.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print('trn_idx:', trn_idx)\n",
    "    print('val_idx:', val_idx)\n",
    "\n",
    "    sparse_features = [\"gender\", \"age\", \"province\", \"city\"]\n",
    "    dense_features = [\"tagid_history_len\"]\n",
    "    varlen_features = [\"tagid_history\", \"tagid_weight\"]\n",
    "    target = ['label']\n",
    "    trn_data = X_train.iloc[trn_idx]\n",
    "    val_data = X_train.iloc[val_idx]\n",
    "\n",
    "    trn_model_input = {name: trn_data[name] for name in sparse_features + dense_features}\n",
    "    val_model_input = {name: val_data[name] for name in sparse_features + dense_features}\n",
    "    test_model_input = {name: X_test[name] for name in sparse_features + dense_features}\n",
    "    for name in varlen_features:\n",
    "        trn_model_input[name] = np.array(trn_data[name].values.tolist())\n",
    "        val_model_input[name] = np.array(val_data[name].values.tolist())\n",
    "        test_model_input[name] = np.array(X_test[name].values.tolist())\n",
    "    model = deepFM(num_dict, embedding_dim_dict, tag_history_max_len=50, dnn_hidden_units=(256, 128),\n",
    "                   l2_reg_linear=0.00001, l2_reg_embedding=1e-2, l2_reg_dnn=0, seed=1024, dnn_dropout=0,\n",
    "                   dnn_activation='relu', dnn_use_bn=False, task='binary')\n",
    "    model.compile('adagrad', \"binary_crossentropy\",\n",
    "                  metrics=[\"binary_crossentropy\", \"AUC\"])\n",
    "    es = EarlyStopping(monitor='val_AUC', patience=2, restore_best_weights=True, mode=\"max\")\n",
    "    history = model.fit(trn_model_input, trn_data[target].values, batch_size=1024, epochs=100,\n",
    "                        verbose=2, validation_data=(val_model_input, val_data[target].values),\n",
    "                        callbacks=[es])\n",
    "    oof_nn[val_idx] = model.predict(val_model_input, 128).reshape(-1)\n",
    "    predictions_nn[:] += model.predict(test_model_input, 128).reshape(-1)\n",
    "print(\"AUC score: {}\".format(roc_auc_score(y, oof_nn)))\n",
    "print(\"F1 score: {}\".format(\n",
    "    f1_score(y, [1 if i >= 0.5 else 0 for i in oof_nn])))\n",
    "print(\"Precision score: {}\".format(precision_score(\n",
    "    y, [1 if i >= 0.5 else 0 for i in oof_nn])))\n",
    "print(\"Recall score: {}\".format(recall_score(\n",
    "    y, [1 if i >= 0.5 else 0 for i in oof_nn])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['category_id'] = [1 if i >= 2.5 else 0 for i in predictions_nn]\n",
    "X_test['user_id'] = X_test['pid']\n",
    "X_test[['user_id', 'category_id']].to_csv('nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
