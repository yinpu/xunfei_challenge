{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adequate-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names\n",
    "from deepctr_torch.models import DeepFM\n",
    "from sklearn.metrics import f1_score, fbeta_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from deepctr_torch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "federal-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.txt', header=None, names=[\n",
    "                    'pid', 'label', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "test = pd.read_csv('data/test.txt', header=None, names=[\n",
    "                   'pid', 'gender', 'age', 'tagid', 'time', 'province', 'city', 'make', 'model'])\n",
    "data = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-tyler",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400000/400000 [00:25<00:00, 15957.21it/s]\n"
     ]
    }
   ],
   "source": [
    "#按tagid时间降序排序，筛选出最近50个tagid，不足补0\n",
    "data['tagid'] = data['tagid'].apply(eval)\n",
    "data['time'] = data['time'].apply(eval)\n",
    "all_tag_id = []\n",
    "for i in tqdm(range(data.shape[0])):\n",
    "    tagid_list = np.array(data.loc[i, 'tagid'])\n",
    "    time_list = np.array(data.loc[i, 'time'])\n",
    "    index = np.argsort(time_list)[::-1][:50]\n",
    "    sort_tagid_list = tagid_list[index]\n",
    "    all_tag_id.extend(sort_tagid_list.tolist()+[0]*(50-len(index)))\n",
    "taglbe = LabelEncoder()\n",
    "new_tag_id = taglbe.fit_transform(all_tag_id).reshape(-1, 50)\n",
    "new_df = pd.DataFrame({\"tagid_history\": new_tag_id.tolist()})\n",
    "new_data = pd.concat([data, new_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "destroyed-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder\n",
    "sparse_features = [\"gender\", \"age\", \"province\", \"city\"]\n",
    "target = ['label']\n",
    "new_data[sparse_features] = new_data[sparse_features].fillna(-1)\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    new_data[feat] = lbe.fit_transform(new_data[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "painted-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "trn_idx: [     0      1      2 ... 299997 299998 299999]\n",
      "val_idx: [     3      9     14 ... 299992 299993 299994]\n",
      "cuda ready...\n",
      "cuda:1\n",
      "Train on 240000 samples, validate on 60000 samples, 235 steps per epoch\n",
      "Epoch 1/10\n",
      "5s - loss:  0.5817 - binary_crossentropy:  0.5752 - auc:  0.7689 - val_binary_crossentropy:  0.5559 - val_auc:  0.7878\n",
      "Epoch 00001: val_auc improved from -inf to 0.78783, saving model to model.ckpt\n",
      "Epoch 2/10\n",
      "6s - loss:  0.5434 - binary_crossentropy:  0.5329 - auc:  0.8099 - val_binary_crossentropy:  0.5525 - val_auc:  0.7922\n",
      "Epoch 00002: val_auc improved from 0.78783 to 0.79215, saving model to model.ckpt\n",
      "Epoch 3/10\n",
      "7s - loss:  0.5259 - binary_crossentropy:  0.5126 - auc:  0.8269 - val_binary_crossentropy:  0.5534 - val_auc:  0.7920\n",
      "Epoch 00003: val_auc did not improve from 0.79215\n",
      "Epoch 00003: early stopping\n",
      "fold n°1\n",
      "trn_idx: [     0      1      2 ... 299996 299998 299999]\n",
      "val_idx: [    10     13     25 ... 299986 299988 299997]\n",
      "cuda ready...\n",
      "cuda:1\n",
      "Train on 240000 samples, validate on 60000 samples, 235 steps per epoch\n",
      "Epoch 1/10\n",
      "5s - loss:  0.5822 - binary_crossentropy:  0.5758 - auc:  0.7692 - val_binary_crossentropy:  0.5539 - val_auc:  0.7903\n",
      "Epoch 00001: val_auc improved from -inf to 0.79033, saving model to model.ckpt\n",
      "Epoch 2/10\n",
      "6s - loss:  0.5428 - binary_crossentropy:  0.5323 - auc:  0.8104 - val_binary_crossentropy:  0.5492 - val_auc:  0.7939\n",
      "Epoch 00002: val_auc improved from 0.79033 to 0.79390, saving model to model.ckpt\n",
      "Epoch 3/10\n",
      "6s - loss:  0.5242 - binary_crossentropy:  0.5109 - auc:  0.8282 - val_binary_crossentropy:  0.5533 - val_auc:  0.7919\n",
      "Epoch 00003: val_auc did not improve from 0.79390\n",
      "Epoch 00003: early stopping\n",
      "fold n°2\n",
      "trn_idx: [     0      3      5 ... 299997 299998 299999]\n",
      "val_idx: [     1      2      4 ... 299961 299977 299982]\n",
      "cuda ready...\n",
      "cuda:1\n",
      "Train on 240000 samples, validate on 60000 samples, 235 steps per epoch\n",
      "Epoch 1/10\n",
      "7s - loss:  0.5817 - binary_crossentropy:  0.5753 - auc:  0.7685 - val_binary_crossentropy:  0.5556 - val_auc:  0.7884\n",
      "Epoch 00001: val_auc improved from -inf to 0.78839, saving model to model.ckpt\n",
      "Epoch 2/10\n",
      "6s - loss:  0.5477 - binary_crossentropy:  0.5378 - auc:  0.8065 - val_binary_crossentropy:  0.5503 - val_auc:  0.7931\n",
      "Epoch 00002: val_auc improved from 0.78839 to 0.79306, saving model to model.ckpt\n",
      "Epoch 3/10\n",
      "7s - loss:  0.5322 - binary_crossentropy:  0.5197 - auc:  0.8222 - val_binary_crossentropy:  0.5519 - val_auc:  0.7923\n",
      "Epoch 00003: val_auc did not improve from 0.79306\n",
      "Epoch 00003: early stopping\n",
      "fold n°3\n",
      "trn_idx: [     0      1      2 ... 299993 299994 299997]\n",
      "val_idx: [     5      6     12 ... 299996 299998 299999]\n",
      "cuda ready...\n",
      "cuda:1\n",
      "Train on 240000 samples, validate on 60000 samples, 235 steps per epoch\n",
      "Epoch 1/10\n",
      "7s - loss:  0.5823 - binary_crossentropy:  0.5758 - auc:  0.7690 - val_binary_crossentropy:  0.5524 - val_auc:  0.7918\n",
      "Epoch 00001: val_auc improved from -inf to 0.79176, saving model to model.ckpt\n",
      "Epoch 2/10\n",
      "8s - loss:  0.5426 - binary_crossentropy:  0.5321 - auc:  0.8111 - val_binary_crossentropy:  0.5482 - val_auc:  0.7950\n",
      "Epoch 00002: val_auc improved from 0.79176 to 0.79495, saving model to model.ckpt\n",
      "Epoch 3/10\n",
      "7s - loss:  0.5234 - binary_crossentropy:  0.5100 - auc:  0.8290 - val_binary_crossentropy:  0.5537 - val_auc:  0.7917\n",
      "Epoch 00003: val_auc did not improve from 0.79495\n",
      "Epoch 00003: early stopping\n",
      "fold n°4\n",
      "trn_idx: [     1      2      3 ... 299997 299998 299999]\n",
      "val_idx: [     0      7      8 ... 299967 299972 299973]\n",
      "cuda ready...\n",
      "cuda:1\n",
      "Train on 240000 samples, validate on 60000 samples, 235 steps per epoch\n",
      "Epoch 1/10\n",
      "6s - loss:  0.5823 - binary_crossentropy:  0.5759 - auc:  0.7692 - val_binary_crossentropy:  0.5553 - val_auc:  0.7882\n",
      "Epoch 00001: val_auc improved from -inf to 0.78817, saving model to model.ckpt\n",
      "Epoch 2/10\n",
      "7s - loss:  0.5432 - binary_crossentropy:  0.5326 - auc:  0.8105 - val_binary_crossentropy:  0.5511 - val_auc:  0.7920\n",
      "Epoch 00002: val_auc improved from 0.78817 to 0.79205, saving model to model.ckpt\n",
      "Epoch 3/10\n",
      "8s - loss:  0.5249 - binary_crossentropy:  0.5116 - auc:  0.8280 - val_binary_crossentropy:  0.5553 - val_auc:  0.7902\n",
      "Epoch 00003: val_auc did not improve from 0.79205\n",
      "Epoch 00003: early stopping\n",
      "AUC score: 0.7913621757777778\n",
      "F1 score: 0.7197748602762839\n",
      "Precision score: 0.7116697945991033\n",
      "Recall score: 0.7280666666666666\n"
     ]
    }
   ],
   "source": [
    "X_train = new_data[~new_data['label'].isna()]\n",
    "X_test = new_data[new_data['label'].isna()]\n",
    "y = X_train['label']\n",
    "KF = StratifiedKFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "oof_nn = np.zeros(len(X_train))\n",
    "predictions_nn = np.zeros((len(X_test)))\n",
    "# 五折交叉验证\n",
    "for fold_, (trn_idx, val_idx) in enumerate(KF.split(X_train.values, y.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    print('trn_idx:', trn_idx)\n",
    "    print('val_idx:', val_idx)\n",
    "\n",
    "    sparse_features = [\"gender\", \"age\", \"province\", \"city\"]\n",
    "    target = ['label']\n",
    "    fixlen_feature_columns = [SparseFeat(feat, new_data[feat].nunique()+5, embedding_dim=64)\n",
    "                              for feat in sparse_features]\n",
    "    varlen_feature_columns = [VarLenSparseFeat(SparseFeat('tagid', vocabulary_size=len(\n",
    "        taglbe.classes_) + 1, embedding_dim=64), maxlen=50, combiner='mean')]\n",
    "    linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "    dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "    feature_names = get_feature_names(\n",
    "        linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "    trn_data = X_train.iloc[trn_idx]\n",
    "    val_data = X_train.iloc[val_idx]\n",
    "    target = ['label']\n",
    "    trn_model_input = {name: trn_data[name] for name in feature_names}  #\n",
    "    trn_model_input[\"tagid\"] = np.array(\n",
    "        trn_data['tagid_history'].values.tolist())\n",
    "    val_model_input = {name: val_data[name] for name in feature_names}\n",
    "    val_model_input[\"tagid\"] = np.array(\n",
    "        val_data['tagid_history'].values.tolist())\n",
    "    test_model_input = {name: X_test[name] for name in feature_names}\n",
    "    test_model_input[\"tagid\"] = np.array(\n",
    "        X_test['tagid_history'].values.tolist())\n",
    "    device = 'cpu'\n",
    "    use_cuda = True\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        print('cuda ready...')\n",
    "        device = 'cuda:0'\n",
    "\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, dnn_hidden_units=(256, 128),\n",
    "                   l2_reg_embedding=1e-2, task='binary', device=device)\n",
    "    model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "                  metrics=[\"binary_crossentropy\", \"auc\"])\n",
    "    es = EarlyStopping(monitor='val_auc', min_delta=0,\n",
    "                       verbose=1, patience=1, mode='max')\n",
    "    mdckpt = ModelCheckpoint(filepath='model.ckpt', monitor='val_auc',\n",
    "                             verbose=1, save_best_only=True, mode='max')\n",
    "    history = model.fit(trn_model_input, trn_data[target].values, batch_size=1024, epochs=10,\n",
    "                        verbose=2, validation_data=(val_model_input, val_data[target].values),\n",
    "                        callbacks=[es, mdckpt])\n",
    "    oof_nn[val_idx] = model.predict(val_model_input, 128).reshape(-1)\n",
    "    predictions_nn[:] += model.predict(test_model_input, 128).reshape(-1)\n",
    "print(\"AUC score: {}\".format(roc_auc_score(y, oof_nn)))\n",
    "print(\"F1 score: {}\".format(\n",
    "    f1_score(y, [1 if i >= 0.5 else 0 for i in oof_nn])))\n",
    "print(\"Precision score: {}\".format(precision_score(\n",
    "    y, [1 if i >= 0.5 else 0 for i in oof_nn])))\n",
    "print(\"Recall score: {}\".format(recall_score(\n",
    "    y, [1 if i >= 0.5 else 0 for i in oof_nn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arctic-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['category_id'] = [1 if i >= 2.5 else 0 for i in predictions_nn]\n",
    "X_test['user_id'] = X_test['pid']\n",
    "X_test[['user_id', 'category_id']].to_csv('nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "protecting-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = {name: X_train[name] for name in sparse_features}  #\n",
    "model_input[\"tagid\"] = np.array(X_train['tagid_history'].values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-coordinator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "monthly-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n",
      "cuda:1\n",
      "Train on 270000 samples, validate on 30000 samples, 264 steps per epoch\n",
      "Epoch 1/10\n",
      "9s - loss:  0.5792 - binary_crossentropy:  0.5726 - auc:  0.7720 - val_binary_crossentropy:  0.5555 - val_auc:  0.7883\n",
      "Epoch 2/10\n",
      "9s - loss:  0.5422 - binary_crossentropy:  0.5316 - auc:  0.8111 - val_binary_crossentropy:  0.5511 - val_auc:  0.7926\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e1c0f9f3b727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"adagrad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle, callbacks)\u001b[0m\n\u001b[1;32m    252\u001b[0m                         \u001b[0mloss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                         \u001b[0mtotal_loss_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fixlen_feature_columns = [SparseFeat(feat, new_data[feat].nunique()+5, embedding_dim=64)\n",
    "                            for feat in sparse_features]\n",
    "varlen_feature_columns = [VarLenSparseFeat(SparseFeat('tagid', vocabulary_size=len(\n",
    "        taglbe.classes_) + 1, embedding_dim=64), maxlen=50, combiner='mean')] \n",
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:1'\n",
    "\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns,dnn_hidden_units=(256, 128),\n",
    "                           l2_reg_embedding=1e-2, task='binary', device=device)\n",
    "\n",
    "model.compile(\"adagrad\", \"binary_crossentropy\", metrics=[\"binary_crossentropy\", \"auc\"])\n",
    "history = model.fit(model_input,X_train[target].values,batch_size=1024,epochs=10,verbose=2,validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "7912"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
